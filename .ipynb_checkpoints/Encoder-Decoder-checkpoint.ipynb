{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for CRNN\n",
    "class Dataset_CRNN(data.Dataset):\n",
    "    \"Characterizes a dataset for PyTorch\"\n",
    "    def __init__(self, data_path, transform=None):\n",
    "        \"Initialization\"\n",
    "        self.transform = transform\n",
    "        #self.frames = frames\n",
    "        self.folders = data_path\n",
    "        self.frames = 10 #For our case since we are computing 10 frames always\n",
    "\n",
    "    def __len__(self):\n",
    "        \"Denotes the total number of samples\"\n",
    "        return len(os.listdir(self.folders))\n",
    "\n",
    "    def read_images(self, data_path, use_transform):\n",
    "        X = []\n",
    "        for i in os.listdir(data_path):\n",
    "            #print(\"file name is \",i)\n",
    "            image = Image.open(os.path.join(data_path,i))\n",
    "            \n",
    "            #print(image.shape)\n",
    "            if use_transform is not None:\n",
    "                image = use_transform(image)\n",
    "                #print(image.size)\n",
    "            image = torch.from_numpy(np.asarray(image))\n",
    "            X.append(image)\n",
    "        X = torch.stack(X, dim=0)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.folders,os.listdir(self.folders)[index])\n",
    "              \n",
    "        # Load data\n",
    "        X = self.read_images(data_path, self.transform)                     # (input) spatial images\n",
    "        \n",
    "        y = np.ones(self.frames)\n",
    "        if 'orig' in data_path:\n",
    "            y = np.zeros(self.frames)\n",
    "        # print(X.shape)\n",
    "        return X, torch.from_numpy(y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_IMG = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    #transforms.CenterCrop(256),\n",
    "    #transforms.ToTensor()\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         #std=[0.229, 0.224, 0.225] )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/chinmay/datatset/train/'\n",
    "train_data = Dataset_CRNN(train_path, transform=TRANSFORM_IMG)\n",
    "# for step, (x, y) in enumerate(data):\n",
    "#     print(x.shape)\n",
    "val_path = '/home/chinmay/datatset/val/'\n",
    "val_data = Dataset_CRNN(val_path, transform=TRANSFORM_IMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_output_shape(num_of_maxpool_2,shape):\n",
    "    return int(shape/(2**num_of_maxpool_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(new_output_shape(4,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Meso4(nn.Module):\n",
    "    def __init__(self,in_channel=3, img_shape = 256, number_of_classes=2):\n",
    "        super(Meso4,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channel,8, kernel_size=(3,3), stride = 1, padding= 1)\n",
    "        self.batch_norm_1 = nn.BatchNorm2d(8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(8,8, kernel_size=(5,5),stride=1, padding=2)\n",
    "        self.batch_norm_2 = nn.BatchNorm2d(8)\n",
    "        self.conv3 = nn.Conv2d(8,16, kernel_size=(5,5),stride=1, padding=2)\n",
    "        self.batch_norm_3 = nn.BatchNorm2d(16)\n",
    "        self.conv4 = nn.Conv2d(16,16, kernel_size=(5,5),stride=1, padding=2)\n",
    "        self.batch_norm_4 = nn.BatchNorm2d(16)\n",
    "        self.max_pool_2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n",
    "        self.max_pool_4 = nn.MaxPool2d(kernel_size=(4, 4), stride=4)\n",
    "        out_shape = new_output_shape(num_of_maxpool_2=4, shape = img_shape)\n",
    "        self.fc_conv = nn.Conv2d(16,number_of_classes,kernel_size=(out_shape,out_shape))\n",
    "        \n",
    "    def forward(self,x_3d):\n",
    "        cnn_embed_seq = []\n",
    "        x_3d = x_3d.permute(0,1,4,2,3)# Required to match shapes\n",
    "        x_3d = x_3d.type(torch.cuda.FloatTensor) #Converting to Float Tensor from Byte Tensor\n",
    "        for t in range(x_3d.size(1)):\n",
    "            x = self.conv1(x_3d[:, t, :, :, :])\n",
    "            x = self.batch_norm_1(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.max_pool_2(x)\n",
    "            x = self.conv2(x)\n",
    "            x = self.batch_norm_2(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.max_pool_2(x)\n",
    "            x = self.conv3(x)\n",
    "            x = self.batch_norm_3(x)\n",
    "            x = self.relu(x)\n",
    "            x = self.max_pool_2(x)\n",
    "            x = self.conv4(x)\n",
    "            x = self.batch_norm_4(x)\n",
    "            x = self.max_pool_2(x)\n",
    "            x = self.fc_conv(x)\n",
    "            #print(\"Shape of x is {}\".format(x.shape))\n",
    "            x = x.view(x.shape[0], -1)\n",
    "            \n",
    "            cnn_embed_seq.append(x)\n",
    "        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=0).transpose_(0, 1)\n",
    "        return cnn_embed_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "epochs = 10\n",
    "log_interval = 5\n",
    "learning_rate = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Meso4(\n",
       "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (batch_norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (conv2): Conv2d(8, 8, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (batch_norm_2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(8, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (batch_norm_3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (batch_norm_4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (max_pool_2): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (max_pool_4): MaxPool2d(kernel_size=(4, 4), stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc_conv): Conv2d(16, 2, kernel_size=(16, 16), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\") \n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = data.DataLoader(train_data, **params)\n",
    "model = Meso4()\n",
    "model.cuda()\n",
    "# for index, (X,y) in enumerate(train_loader):\n",
    "#     y_pred = model(X)\n",
    "#     print (y_pred.shape)\n",
    "# Shape was torch.Size([4, 10, 2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_median(numpy_array = []): #This is expected to take an array of array. So,\n",
    "    #print(\"Input array is {}\".format(numpy_array))\n",
    "    output = []\n",
    "    for array in numpy_array:\n",
    "        counts = np.bincount(array)\n",
    "        output.append(np.argmax(counts))\n",
    "    return torch.from_numpy(np.asarray(output)).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    model.train() #Put the model in training mode\n",
    "    losses = []\n",
    "    scores = []\n",
    "    N_count = 0   # counting total trained sample in one epoch\n",
    "    for batch_idx, (X, y) in enumerate(train_loader):\n",
    "        # distribute data to device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        N_count += X.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)   # output has dim = (batch, number of classes)\n",
    "        #print(output)\n",
    "        #print(y.shape)\n",
    "        loss_train = 0 \n",
    "        for items in range(output.shape[1]):\n",
    "            loss_train = loss_train + loss_function(output[:,items,:], y[:,items]).item()\n",
    "        \n",
    "        losses.append(loss_train)\n",
    "\n",
    "        # to compute accuracy\n",
    "        y_pred = torch.max(output, 2)[1]  # y_pred != output\n",
    "        # We take the modal value of all predictions. So,\n",
    "        y = find_median(y)\n",
    "        y_pred = find_median(y_pred)\n",
    "        print(\"Predicted is {}\".format(y_pred))\n",
    "        \n",
    "        step_score = accuracy_score(y.cpu().data.squeeze().numpy(), y_pred.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)         # computed on CPU\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # show information\n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "\n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, device, optimizer, test_loader):\n",
    "    # set model as testing mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    all_y = []\n",
    "    all_y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_loader:\n",
    "            # distribute data to device\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            output = model(X)\n",
    "            print(output.shape)\n",
    "            print(y.shape)\n",
    "            loss = loss_function(output, y)\n",
    "            test_loss += loss.item()                 # sum up batch loss\n",
    "            y_pred = output.max(2, keepdim=True)[1]  # (y_pred != output) get the index of the max log-probability\n",
    "\n",
    "            # collect all y and y_pred in all batches\n",
    "            all_y.extend(y)\n",
    "            all_y_pred.extend(y_pred)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    # compute accuracy\n",
    "    all_y = torch.stack(all_y, dim=0)\n",
    "    all_y_pred = torch.stack(all_y_pred, dim=0)\n",
    "    test_score = accuracy_score(all_y.cpu().data.squeeze().numpy(), all_y_pred.cpu().data.squeeze().numpy())\n",
    "\n",
    "    # show information\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_y), test_loss, 100* test_score))\n",
    "\n",
    "    # save Pytorch models of best record\n",
    "#     torch.save(cnn_encoder.state_dict(), os.path.join(save_model_path, 'cnn_encoder_epoch{}.pth'.format(epoch + 1)))  # save spatial_encoder\n",
    "#     torch.save(rnn_decoder.state_dict(), os.path.join(save_model_path, 'rnn_decoder_epoch{}.pth'.format(epoch + 1)))  # save motion_encoder\n",
    "#     torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(epoch + 1)))      # save optimizer\n",
    "#     print(\"Epoch {} model saved!\".format(epoch + 1))\n",
    "\n",
    "    return test_loss, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted is tensor([1, 1, 0, 0])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-ef6d05568063>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# train, test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mepoch_test_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_test_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-163-7ee4bf7878da>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(log_interval, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_score\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# computed on CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # train, test model\n",
    "    train_losses, train_scores = train(log_interval, model, device, train_loader, optimizer, epoch)\n",
    "    epoch_test_loss, epoch_test_score = validation(model, device, optimizer, valid_loader)\n",
    "\n",
    "    # save results\n",
    "    epoch_train_losses.append(train_losses)\n",
    "    epoch_train_scores.append(train_scores)\n",
    "    epoch_test_losses.append(epoch_test_loss)\n",
    "    epoch_test_scores.append(epoch_test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.plot(np.arange(1, epochs + 1), A[:, -1])  # train loss (on epoch end)\n",
    "plt.plot(np.arange(1, epochs + 1), C)         #  test loss (on epoch end)\n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'test'], loc=\"upper left\")\n",
    "# 2nd figure\n",
    "plt.subplot(122)\n",
    "plt.plot(np.arange(1, epochs + 1), B[:, -1])  # train accuracy (on epoch end)\n",
    "plt.plot(np.arange(1, epochs + 1), D)         #  test accuracy (on epoch end)\n",
    "plt.title(\"training scores\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'test'], loc=\"upper left\")\n",
    "title = \"./fig_UCF101_ResNetCRNN.png\"\n",
    "plt.savefig(title, dpi=600)\n",
    "# plt.close(fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,1,2,1,1,1,3,2,2,1])\n",
    "counts = np.bincount(a)\n",
    "print (np.argmax(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
